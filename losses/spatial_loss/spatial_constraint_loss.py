"""
Spatial Constraint Loss for TextBraTS

This module implements spatial constraint loss that penalizes predictions
outside anatomically plausible regions defined by per-sample atlas masks.

The loss guides the model to predict tumor segmentations only in regions
mentioned in the radiology report text (e.g., "Right Frontal Lobe").

Author: TextBraTS Spatial Loss Implementation
Date: 2025-12-07
"""

import os
import torch
import torch.nn as nn
import nibabel as nib
import numpy as np
from typing import Dict, List, Optional


class SpatialConstraintLoss(nn.Module):
    """
    Spatial constraint loss that penalizes predictions outside anatomically
    plausible regions defined by atlas masks.

    Formula:
        L_spatial = (1/B) Σ_b [ Σ_c (P_c × (1 - A_c)) / (Σ_c P_c + ε) ]

    Where:
        - B = batch size
        - c = channel (TC, WT, ET)
        - P = predicted probabilities [0, 1]
        - A = binary atlas mask (1 = allowed, 0 = forbidden)
        - ε = small constant for numerical stability

    The loss measures "leakage" - predictions that appear in forbidden zones
    (regions not mentioned in the radiology report). It's normalized by total
    prediction volume to handle different tumor sizes fairly.
    """

    def __init__(
        self,
        atlas_masks_dir: str,
        device: str = 'cuda',
        cache_masks: bool = True,
        epsilon: float = 1e-6
    ):
        """
        Initialize the spatial constraint loss.

        Args:
            atlas_masks_dir: Directory containing {sample_id}_atlas_mask.nii.gz files
                            Generated by generate_sample_atlas_masks.py
            device: Device to load masks on ('cuda' or 'cpu' or specific GPU like 'cuda:0')
            cache_masks: If True, cache loaded masks in memory for speed
                        Recommended True for datasets that fit in RAM (~2-3 GB for 369 samples)
            epsilon: Small constant for numerical stability in division
        """
        super().__init__()
        self.atlas_masks_dir = atlas_masks_dir
        self.device = device
        self.cache_masks = cache_masks
        self.epsilon = epsilon

        # Cache for loaded masks
        self._mask_cache: Dict[str, torch.Tensor] = {}

        # Whole-brain fallback mask (all ones)
        # Will be created lazily when needed
        self._whole_brain_mask: Optional[torch.Tensor] = None

        print(f"SpatialConstraintLoss initialized:")
        print(f"  Atlas masks directory: {atlas_masks_dir}")
        print(f"  Device: {device}")
        print(f"  Caching enabled: {cache_masks}")

    def _get_whole_brain_mask(self, shape: tuple) -> torch.Tensor:
        """
        Create whole-brain fallback mask (all voxels allowed).

        This is used when an atlas mask is missing for a sample,
        effectively disabling spatial constraint for that sample.

        Args:
            shape: Shape of the mask (typically (3, 128, 128, 128))

        Returns:
            Tensor of all ones with the specified shape
        """
        if self._whole_brain_mask is None or self._whole_brain_mask.shape != shape:
            self._whole_brain_mask = torch.ones(shape, dtype=torch.float32)
        return self._whole_brain_mask

    def load_atlas_mask(self, sample_id: str) -> torch.Tensor:
        """
        Load atlas mask for a sample.

        Args:
            sample_id: Sample identifier (e.g., "BraTS20_Training_001")

        Returns:
            Atlas mask tensor of shape (3, 128, 128, 128) where:
                - Channel 0: TC (Tumor Core) allowed regions
                - Channel 1: WT (Whole Tumor) allowed regions
                - Channel 2: ET (Enhancing Tumor) allowed regions
                - Values: 1 = allowed, 0 = forbidden
        """
        # Check cache first
        if self.cache_masks and sample_id in self._mask_cache:
            return self._mask_cache[sample_id]

        # Construct file path
        mask_path = os.path.join(self.atlas_masks_dir, f"{sample_id}_atlas_mask.nii.gz")

        # Check if file exists
        if not os.path.exists(mask_path):
            print(f"Warning: Atlas mask not found for {sample_id} at {mask_path}")
            print(f"         Using whole-brain fallback (no spatial constraint)")
            # Return whole-brain mask (no spatial constraint)
            fallback_mask = self._get_whole_brain_mask((3, 128, 128, 128))
            return fallback_mask.to(self.device)

        try:
            # Load NIfTI file
            nii = nib.load(mask_path)
            mask_data = nii.get_fdata().astype(np.float32)  # Shape: (3, 128, 128, 128)

            # Convert to torch tensor
            mask_tensor = torch.from_numpy(mask_data).float()

            # Move to device
            mask_tensor = mask_tensor.to(self.device)

            # Cache if enabled
            if self.cache_masks:
                self._mask_cache[sample_id] = mask_tensor

            return mask_tensor

        except Exception as e:
            print(f"Error loading atlas mask for {sample_id}: {e}")
            print(f"Using whole-brain fallback")
            fallback_mask = self._get_whole_brain_mask((3, 128, 128, 128))
            return fallback_mask.to(self.device)

    def forward(self, logits: torch.Tensor, sample_ids: List[str]) -> torch.Tensor:
        """
        Compute spatial constraint loss.

        Args:
            logits: Raw model outputs (before sigmoid), shape (B, 3, H, W, D)
                   Typically (B, 3, 128, 128, 128) for BraTS
            sample_ids: List of sample IDs, length B
                       e.g., ["BraTS20_Training_001", "BraTS20_Training_002"]

        Returns:
            Scalar loss value representing spatial constraint violation
            Higher values indicate more predictions in forbidden zones
        """
        # Convert logits to probabilities
        probs = torch.sigmoid(logits)  # Shape: (B, 3, 128, 128, 128)

        batch_size = probs.shape[0]
        total_loss = 0.0
        valid_samples = 0

        for b in range(batch_size):
            sample_id = sample_ids[b]

            # Load atlas mask for this sample
            atlas_mask = self.load_atlas_mask(sample_id)  # Shape: (3, 128, 128, 128)

            # Get predictions for this sample
            pred_probs = probs[b]  # Shape: (3, 128, 128, 128)

            # Compute forbidden zone (complement of allowed regions)
            forbidden_zone = 1.0 - atlas_mask  # Shape: (3, 128, 128, 128)

            # Measure prediction "leakage" into forbidden zones
            leakage = pred_probs * forbidden_zone  # Shape: (3, 128, 128, 128)

            # Sum across spatial dimensions for each channel
            total_leakage = torch.sum(leakage, dim=(1, 2, 3))  # Shape: (3,)
            total_pred = torch.sum(pred_probs, dim=(1, 2, 3)) + self.epsilon  # Shape: (3,)

            # Normalize by total prediction volume per channel
            # This makes the loss invariant to tumor size
            normalized_leakage = total_leakage / total_pred  # Shape: (3,)

            # Average across channels
            sample_loss = torch.mean(normalized_leakage)

            total_loss += sample_loss
            valid_samples += 1

        # Average across batch
        if valid_samples > 0:
            return total_loss / valid_samples
        else:
            return torch.tensor(0.0, device=self.device, requires_grad=True)

    def get_cache_stats(self) -> Dict[str, int]:
        """
        Get statistics about the mask cache.

        Returns:
            Dictionary with cache statistics
        """
        return {
            'cached_masks': len(self._mask_cache),
            'cache_enabled': self.cache_masks
        }

    def clear_cache(self):
        """Clear the mask cache to free memory."""
        self._mask_cache.clear()
        self._whole_brain_mask = None
        print("Spatial loss mask cache cleared")
